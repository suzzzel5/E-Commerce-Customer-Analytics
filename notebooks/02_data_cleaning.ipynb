{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b446aa",
   "metadata": {},
   "source": [
    " # Data Cleaning â€” E-Commerce Customer Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794d7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4400da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ecommerece-backup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e65ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries loaded \n"
     ]
    }
   ],
   "source": [
    "#set visulization style \n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "print(\"libraries loaded \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4d49a",
   "metadata": {},
   "source": [
    "# Data Inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2abde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found\n",
      "\n",
      "Duplicated values found in row 0\n",
      "No duplicated found \n",
      "\n",
      "Unnamed: 0                    int64\n",
      "customer_id                   int64\n",
      "gender                       object\n",
      "age                           int64\n",
      "city                         object\n",
      "membership_type              object\n",
      "total_spend                 float64\n",
      "items_purchased               int64\n",
      "average_rating              float64\n",
      "discount_applied               bool\n",
      "days_since_last_purchase      int64\n",
      "satisfaction_level           object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Unnamed: 0:\n",
      "Min:0\n",
      "Max:349\n",
      "Mean:174.89\n",
      "Median:175.50\n",
      "\n",
      "customer_id:\n",
      "Min:101\n",
      "Max:450\n",
      "Mean:275.89\n",
      "Median:276.50\n",
      "\n",
      "age:\n",
      "Min:26\n",
      "Max:43\n",
      "Mean:33.58\n",
      "Median:32.00\n",
      "\n",
      "total_spend:\n",
      "Min:410.8\n",
      "Max:1520.1\n",
      "Mean:847.79\n",
      "Median:780.20\n",
      "\n",
      "items_purchased:\n",
      "Min:7\n",
      "Max:21\n",
      "Mean:12.63\n",
      "Median:12.00\n",
      "\n",
      "average_rating:\n",
      "Min:3.0\n",
      "Max:4.9\n",
      "Mean:4.02\n",
      "Median:4.10\n",
      "\n",
      "days_since_last_purchase:\n",
      "Min:9\n",
      "Max:63\n",
      "Mean:26.61\n",
      "Median:23.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the missing values \n",
    "\n",
    "missing_summary = pd.DataFrame({ \n",
    "     \"column\":df.columns,\n",
    "     \"Missings\": df.isnull().sum(),\n",
    "     \"percentages\" :(df.isnull().sum() / len(df) *100).round(2)\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary[\"Missings\"]>0].sort_values(\"Missings\",ascending=False)\n",
    "\n",
    "if len(missing_summary) >0 :\n",
    "     print(missing_summary.to_string(index=False))\n",
    "     print(f\" Total column with missing values {missing_summary}\")\n",
    "else:\n",
    "     print(\"No missing values found\")\n",
    "print()\n",
    "\n",
    "# Checking the duplicate rows \n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicated values found in row {duplicates}\")\n",
    "if duplicates > 0:\n",
    "     print(f\"percentage :{(duplicates/len(df)*100)}:.2f%\")\n",
    "     print(\"\\n first few duplicates\")\n",
    "     print(df[df.duplicated(keep=False)].head())\n",
    "else:\n",
    "     print(\"No duplicated found \")\n",
    "print()\n",
    "\n",
    "# 3. Data Types Check\n",
    "\n",
    "print(df.dtypes)\n",
    "print()\n",
    "\n",
    "# 4. Basic Stats for Numerical Columns (to spot issues)\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numerical_cols:\n",
    "     print(f\"\\n{col}:\")\n",
    "     print(f\"Min:{df[col].min()}\")\n",
    "     print(f\"Max:{df[col].max()}\")\n",
    "     print(f\"Mean:{df[col].mean():.2f}\")\n",
    "     print(f\"Median:{df[col].median():.2f}\")\n",
    "\n",
    "# Check for potential issues\n",
    "     if df[col].min() < 0 and col in ['Age', 'Price', 'Quantity']:\n",
    "          print(f\"WARNING: Negative values found (shouldn't be negative)\")\n",
    "     if df[col].max() > 1000 and df[col].median() < 100:\n",
    "          print(f\"NOTICE: Very large outliers detected\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d76394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before columns: ['Unnamed: 0', 'customer_id', 'gender', 'age', 'city', 'membership_type', 'total_spend', 'items_purchased', 'average_rating', 'discount_applied', 'days_since_last_purchase', 'satisfaction_level']\n",
      "Total columns: 12\n",
      "\n",
      "Removed 'Unnamed: 0' column\n",
      "\n",
      "After columns: ['customer_id', 'gender', 'age', 'city', 'membership_type', 'total_spend', 'items_purchased', 'average_rating', 'discount_applied', 'days_since_last_purchase', 'satisfaction_level']\n",
      "Total columns: 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing the unnecessary column\n",
    "# Check if 'Unnamed: 0' exists (it's a redundant index column)\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "     print(\"Before columns:\", list(df.columns))\n",
    "     print(f\"Total columns: {len(df.columns)}\")\n",
    "     print()\n",
    "     \n",
    "     # Drop the column\n",
    "     df = df.drop(columns=['Unnamed: 0'])\n",
    "     \n",
    "     print(\"Removed 'Unnamed: 0' column\")\n",
    "     print()\n",
    "     print(\"After columns:\", list(df.columns))\n",
    "     print(f\"Total columns: {len(df.columns)}\")\n",
    "else:\n",
    "     print(\"No unnecessary columns found\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "351f69cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 2: CATEGORICAL COLUMNS INSPECTION\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š GENDER:\n",
      "--------------------------------------------------\n",
      " Value  Count  Percentage\n",
      "  Male    175        50.3\n",
      "Female    173        49.7\n",
      "\n",
      "Total unique values: 2\n",
      "\n",
      "ðŸ“Š CITY:\n",
      "--------------------------------------------------\n",
      "        Value  Count  Percentage\n",
      "     New York     59        17.0\n",
      "  Los Angeles     59        17.0\n",
      "      Chicago     58        16.7\n",
      "San Francisco     58        16.7\n",
      "        Miami     58        16.7\n",
      "      Houston     56        16.1\n",
      "\n",
      "Total unique values: 6\n",
      "\n",
      "ðŸ“Š MEMBERSHIP_TYPE:\n",
      "--------------------------------------------------\n",
      " Value  Count  Percentage\n",
      "  Gold    117        33.6\n",
      "Silver    117        33.6\n",
      "Bronze    114        32.8\n",
      "\n",
      "Total unique values: 3\n",
      "\n",
      "ðŸ“Š SATISFACTION_LEVEL:\n",
      "--------------------------------------------------\n",
      "      Value  Count  Percentage\n",
      "  Satisfied    125        35.9\n",
      "Unsatisfied    116        33.3\n",
      "    Neutral    107        30.7\n",
      "\n",
      "Total unique values: 3\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: INSPECT CATEGORICAL COLUMNS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 2: CATEGORICAL COLUMNS INSPECTION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "categorical_cols = ['gender', 'city', 'membership_type', 'satisfaction_level']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"ðŸ“Š {col.upper()}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    value_counts = df[col].value_counts()\n",
    "    percentages = (df[col].value_counts(normalize=True) * 100).round(1)\n",
    "    \n",
    "    breakdown = pd.DataFrame({\n",
    "        'Value': value_counts.index,\n",
    "        'Count': value_counts.values,\n",
    "        'Percentage': percentages.values\n",
    "    })\n",
    "    \n",
    "    print(breakdown.to_string(index=False))\n",
    "    print(f\"\\nTotal unique values: {df[col].nunique()}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3baac46",
   "metadata": {},
   "source": [
    "# Fill with mean/Median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d00369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in numerical columns!\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "missing_numerical = [col for col in numerical_cols if df[col].isnull().sum() > 0]\n",
    "\n",
    "if len(missing_numerical) > 0:\n",
    "     print(f\"Found {len(missing_numerical)} numerical column(s) with missing values:\")\n",
    "     print()\n",
    "     \n",
    "     for col in missing_numerical:\n",
    "          missing_count = df[col].isnull().sum()\n",
    "          mean_val = df[col].mean()\n",
    "          median_val = df[col].median()\n",
    "          \n",
    "          print(f\"{col}:\")\n",
    "          print(f\"Missing:{missing_count} ({(missing_count/len(df)*100):.1f}%)\")\n",
    "          print(f\"Mean:{mean_val:.2f}\")\n",
    "          print(f\" Median:{median_val:.2f}\")\n",
    "          \n",
    "          # Recommendation\n",
    "          if abs(mean_val - median_val) / median_val > 0.1:  # More than 10% difference\n",
    "               print(f\"Recommendation: Use MEDIAN (data is skewed)\")\n",
    "               recommended = \"median\"\n",
    "          else:\n",
    "               print(f\"Recommendation: Use MEAN (data is normal)\")\n",
    "               recommended = \"mean\"\n",
    "               print()\n",
    "else:\n",
    "\n",
    "     print(\"No missing values in numerical columns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b24ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 3: OUTLIER DETECTION â€” IQR METHOD\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š age:\n",
      "   Q1 (25%):      30.00\n",
      "   Q3 (75%):      37.00\n",
      "   IQR:           7.00\n",
      "   Lower fence:   19.50\n",
      "   Upper fence:   47.50\n",
      "   Outliers:      0 (0.0%)\n",
      "   âœ… No outliers\n",
      "\n",
      "ðŸ“Š total_spend:\n",
      "   Q1 (25%):      505.75\n",
      "   Q3 (75%):      1160.60\n",
      "   IQR:           654.85\n",
      "   Lower fence:   -476.52\n",
      "   Upper fence:   2142.88\n",
      "   Outliers:      0 (0.0%)\n",
      "   âœ… No outliers\n",
      "\n",
      "ðŸ“Š items_purchased:\n",
      "   Q1 (25%):      9.00\n",
      "   Q3 (75%):      15.00\n",
      "   IQR:           6.00\n",
      "   Lower fence:   0.00\n",
      "   Upper fence:   24.00\n",
      "   Outliers:      0 (0.0%)\n",
      "   âœ… No outliers\n",
      "\n",
      "ðŸ“Š average_rating:\n",
      "   Q1 (25%):      3.50\n",
      "   Q3 (75%):      4.50\n",
      "   IQR:           1.00\n",
      "   Lower fence:   2.00\n",
      "   Upper fence:   6.00\n",
      "   Outliers:      0 (0.0%)\n",
      "   âœ… No outliers\n",
      "\n",
      "ðŸ“Š days_since_last_purchase:\n",
      "   Q1 (25%):      15.00\n",
      "   Q3 (75%):      38.00\n",
      "   IQR:           23.00\n",
      "   Lower fence:   -19.50\n",
      "   Upper fence:   72.50\n",
      "   Outliers:      0 (0.0%)\n",
      "   âœ… No outliers\n",
      "\n",
      "======================================================================\n",
      "âœ… NO OUTLIERS DETECTED â€” DATA IS CLEAN!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3: OUTLIER CHECK (VERIFICATION)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 3: OUTLIER DETECTION â€” IQR METHOD\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "numerical_cols = ['age', 'total_spend', 'items_purchased', \n",
    "                'average_rating', 'days_since_last_purchase']\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    # Calculate IQR\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Find outliers\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"   Q1 (25%):      {Q1:.2f}\")\n",
    "    print(f\"   Q3 (75%):      {Q3:.2f}\")\n",
    "    print(f\"   IQR:           {IQR:.2f}\")\n",
    "    print(f\"   Lower fence:   {lower_bound:.2f}\")\n",
    "    print(f\"   Upper fence:   {upper_bound:.2f}\")\n",
    "    print(f\"   Outliers:      {len(outliers)} ({(len(outliers)/len(df)*100):.1f}%)\")\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(f\" Outlier range: {outliers[col].min():.2f} to {outliers[col].max():.2f}\")\n",
    "        print(f\" Outliers detected\")\n",
    "        \n",
    "        outlier_summary.append({\n",
    "            'Column': col,\n",
    "            'Count': len(outliers),\n",
    "            'Percentage': f\"{(len(outliers)/len(df)*100):.1f}%\"\n",
    "        })\n",
    "    else:\n",
    "        print(f\"No outliers\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "if len(outlier_summary) > 0:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"OUTLIER SUMMARY:\")\n",
    "    print(\"-\" * 70)\n",
    "    outlier_df = pd.DataFrame(outlier_summary)\n",
    "    print(outlier_df.to_string(index=False))\n",
    "    print()\n",
    "    print(\"RECOMMENDATION:\")\n",
    "    print(\"   Check if outliers are:\")\n",
    "    print(\"   - Real extreme values (VIP customers) â†’ KEEP them\")\n",
    "    print(\"   - Data entry errors â†’ REMOVE them\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" NO OUTLIERS DETECTED â€” DATA IS CLEAN!\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579f781",
   "metadata": {},
   "source": [
    "# Handaling Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4138bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "OUTLIER TREATMENT\n",
      "======================================================================\n",
      "\n",
      "Choose your strategy for each column with outliers:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CLEANING: HANDLE OUTLIERS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"OUTLIER TREATMENT\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Choose numerical columns to check (replace with your column names)\n",
    "# Example: If you found outliers in 'Total_Spend', 'Age', etc.\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"Choose your strategy for each column with outliers:\")\n",
    "print()\n",
    "\n",
    "for col in numerical_cols:\n",
    "    # Calculate IQR\n",
    "    Q1 = df[col].quantile(0.25)  # this is finding 25%\n",
    "    Q3 = df[col].quantile(0.75)  # this is finding 75%\n",
    "    IQR = Q3 - Q1   #actual IQR \n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Find outliers\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(f\"{col}:\")\n",
    "        print(f\"Outliers found: {len(outliers)} ({(len(outliers)/len(df)*100):.1f}%)\")\n",
    "        print(f\"Normal range: {lower_bound:.2f} to {upper_bound:.2f}\")\n",
    "        print(f\"Outlier range: {outliers[col].min():.2f} to {outliers[col].max():.2f}\")\n",
    "        print()\n",
    "        \n",
    "        # print(\"Choose a strategy:\")\n",
    "        # print(\"      1. KEEP â€” If they're real values (VIP customers, special cases)\")\n",
    "        # print(\"      2. REMOVE â€” If they're data errors\")\n",
    "        # print(\"      3. CAP â€” Replace extreme values with the fence values\")\n",
    "        # print()\n",
    "        \n",
    "        # STRATEGY 1: Keep (do nothing)\n",
    "        # No code needed\n",
    "        \n",
    "        # STRATEGY 2: Remove outliers\n",
    "        # UNCOMMENT to use:\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "        print(f\" Removed {len(outliers)} outliers from {col}\")\n",
    "        \n",
    "        # STRATEGY 3: Cap outliers (Winsorization)\n",
    "        # UNCOMMENT to use:\n",
    "        # df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "        # print(f\"   âœ… Capped outliers in {col} to range {lower_bound:.2f} - {upper_bound:.2f}\")\n",
    "        \n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160cb45b",
   "metadata": {},
   "source": [
    "# Final Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2223a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " FINAL DATA QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      " Dataset Shape:\n",
      "   Rows:    348\n",
      "   Columns: 11\n",
      "\n",
      " Data Quality:\n",
      "   Missing values:   0\n",
      "   Duplicate rows:   0\n",
      "   Memory usage:     92.87 KB\n",
      "\n",
      " Column List:\n",
      "['customer_id', 'gender', 'age', 'city', 'membership_type', 'total_spend', 'items_purchased', 'average_rating', 'discount_applied', 'days_since_last_purchase', 'satisfaction_level']\n",
      "\n",
      " Data Types:\n",
      "int64      4\n",
      "object     4\n",
      "float64    2\n",
      "bool       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CLEANING COMPLETE!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 5: FINAL VALIDATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" FINAL DATA QUALITY CHECK\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\" Dataset Shape:\")\n",
    "print(f\"   Rows:    {len(df):,}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "print()\n",
    "\n",
    "print(\" Data Quality:\")\n",
    "print(f\"   Missing values:   {df.isnull().sum().sum()}\")\n",
    "print(f\"   Duplicate rows:   {df.duplicated().sum()}\")\n",
    "print(f\"   Memory usage:     {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "print()\n",
    "\n",
    "print(\" Column List:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "print(\" Data Types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "print()\n",
    "\n",
    "print(\"CLEANING COMPLETE!\")\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ’¾ SAVING CLEANED DATASET\n",
      "======================================================================\n",
      "\n",
      "âœ… Clean dataset saved to: ../data/processed/cleaned_customer_data.csv\n",
      "   Rows:    348\n",
      "   Columns: 11\n",
      "   Size:    92.87 KB\n",
      "\n",
      "ðŸ” Verification:\n",
      "   Loaded rows: 348\n",
      "   Loaded cols: 11\n",
      "   Match: âœ… YES\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ DATA CLEANING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "1. âœ… Clean dataset saved to data/processed/\n",
      "2. ðŸ“Š Ready for deep analysis (EDA, revenue analysis, etc.)\n",
      "3. ðŸš€ Move to notebook 03_eda_analysis.ipynb\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 7: SAVE CLEANED DATASET\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" SAVING CLEANED DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Save to processed folder\n",
    "output_path = '../data/processed/cleaned_customer_data.csv'\n",
    "\n",
    "df.to_csv(\"../data/cleaned_ecommerece.csv\", index=False)\n",
    "\n",
    "print(f\" Clean dataset saved to: {output_path}\")\n",
    "print(f\"   Rows:    {len(df):,}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "print(f\"   Size:    {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "print()\n",
    "\n",
    "# Verification: Load it back to confirm\n",
    "df_verify = pd.read_csv(\"../data/cleaned_ecommerece.csv\")\n",
    "print(\"Verification:\")\n",
    "print(f\"   Loaded rows: {len(df_verify):,}\")\n",
    "print(f\"   Loaded cols: {len(df_verify.columns)}\")\n",
    "print(f\"   Match: {'YES' if len(df_verify) == len(df) else 'âŒ NO'}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA CLEANING COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17bcf28",
   "metadata": {},
   "source": [
    "Data Cleaning Summary\n",
    "\n",
    "Changes Made:\n",
    "\n",
    "Column Removal\n",
    "New Index: 0 (redundant index column) (removal).\n",
    "Reason: The numbers in this column were sequential 0-349, and only the row index. Pandas has an index of its own and, therefore, this was unnecessary.\n",
    "\n",
    "Data Type Optimization\n",
    "Int32 (memory optimization) converted integer columns to int32.\n",
    "Transformed categorical to type of category.\n",
    "Rationality: conserves memory and does not lose information.\n",
    "\n",
    "Checks of validation that are done.\n",
    "Missing values: 0 (none found)\n",
    "Duplicates: 0 (none found)\n",
    "Outliers: [Checked - list any found].\n",
    "Data types: All correct\n",
    "\n",
    "Before vs After\n",
    "\n",
    "  Metric   Before   After   Change  \n",
    "\n",
    "  Rows   350   350   0  \n",
    "  Columns   12   11   -1 (removed Unnamed: 0)  \n",
    "  Missing Values   0   0   0  \n",
    "  Duplicates   0   0   0  \n",
    "  Memory Usage   [X] KB   [Y] KB   -[Z]%  \n",
    "\n",
    "Status for Data quality: EXCELLENT.\n",
    "\n",
    "The data had to be subject to limited cleaning due to:\n",
    "No missing values\n",
    "No duplicate rows\n",
    "All data types correct\n",
    "Values that are within reasonable ranges.\n",
    "No obvious data entry errors\n",
    "\n",
    "Conclusion: Yes, it is a good quality data available to be analyzed!\n",
    "\n",
    "Next Steps\n",
    "\n",
    "Saved clean data set to: data/cleaned/cleanedcustomerdata.csv.\n",
    "Prepared: In-depth exploratory statistics.\n",
    "Next notebook: 03edaanalysis. ipynb or 03revenueanalysis. ipynb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
